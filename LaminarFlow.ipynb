{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting laminarflow/_cruisecontrol.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile laminarflow/_cruisecontrol.py\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "    \n",
    "class _tf_temp():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "class _method_temp():\n",
    "    def __init__(self, name, method_name):\n",
    "        self.name = name\n",
    "        self.method_name = method_name\n",
    "\n",
    "class CruiseControl():\n",
    "    \"\"\"\n",
    "    Laminar Flow's Cruise Control method automates several\n",
    "    time saving tasks for Tensorflow, allowing for quicker\n",
    "    prototyping and testing.\n",
    "    \n",
    "    Among these abilities is automatic saving in an encapsulated\n",
    "    tensorflow session. This makes it so you don't need to\n",
    "    keep open a session to keep the values. However, it does\n",
    "    require you to use `tf.get_variable` to define variables\n",
    "    instead of `tf.Variable` directly.\n",
    "    \n",
    "    On top of that, automatic initialization of uninitialized\n",
    "    variables allows for this structure to be dynamically updated\n",
    "    and have no cat and mouse hunt for errors.\n",
    "    \n",
    "    Pickling and unpickling has been implemented in this class\n",
    "    under the strict conditions that all non-variable tensors\n",
    "    used in args to the `add` function are the result of previous\n",
    "    functions input to the `add` function and all `function`s used\n",
    "    have to either be functions or methods bound to results of\n",
    "    previous calls to add. That is, when calling `add`, only use\n",
    "    direct attributes of that CruiseControl instance or variables\n",
    "    controlled by it and only use functions or methods controlled\n",
    "    by that instance as well.\n",
    "    \n",
    "    Since TensorFlow objects are not pickleable directly, args\n",
    "    and kwargs to `add` have to be easily sanitized, unless you\n",
    "    want to do it yourself. More complex sanitization is possible,\n",
    "    if somewhat difficult. To sanitize yourself, currently you must\n",
    "    create the magic functions in whatever you pass to `add` if\n",
    "    it isn't automatically taken care of already.\n",
    "    \n",
    "    More documentation to follow. This all needs to be reworded\n",
    "    to make more sense.\n",
    "    \"\"\"\n",
    "#Constructor\n",
    "    def __init__(self, save_file_name, unique_identifier = None):\n",
    "        #collect_variables()\n",
    "        self._vars = set()\n",
    "        self._var_pkl = list()\n",
    "        self._file_name = save_file_name\n",
    "        self.saver = None\n",
    "        self._uuid = unique_identifier if unique_identifier else hex(id(self))[2:]\n",
    "        try:\n",
    "            with tf.variable_scope(self._uuid):\n",
    "                with tf.variable_scope(self._uuid):\n",
    "                    tf.get_variable(\"initialized\",shape=[1])\n",
    "        except:\n",
    "            raise NameError(\"Error: {} is an invalid unique identifier.\".format(self._uuid))\n",
    "#Structure\n",
    "    def add(self, name, function, *args, **kwargs):\n",
    "        if hasattr(self, name):\n",
    "            raise AttributeError(\"Error: {} already defined.\".format(name))\n",
    "        current = set(tf.all_variables())\n",
    "        #sanitize\n",
    "        sanitized_args = [self.sanitize(arg) for arg in args]\n",
    "        sanitized_kwargs = {key:self.sanitize(value) for key,value in kwargs.items()}\n",
    "        sanitized_func = self.sanitize(function)\n",
    "        #Test.\n",
    "        try:\n",
    "            pkl.dumps([sanitized_func, sanitized_args, sanitized_kwargs])\n",
    "        except:\n",
    "            raise ValueError(\"Error: Unable to sanitize.\")\n",
    "        #unsanitize\n",
    "        unsanitized_func = self.unsanitize(function)\n",
    "        unsanitized_args = [self.unsanitize(arg) for arg in args]\n",
    "        unsanitized_kwargs = {key:self.unsanitize(value) for key,value in kwargs.items()}\n",
    "        with tf.variable_scope(self._uuid):\n",
    "            with tf.variable_scope(name):\n",
    "                setattr(self, name, unsanitized_func(*unsanitized_args, **unsanitized_kwargs))\n",
    "        self._vars |= set(tf.all_variables()) - current\n",
    "        self._var_pkl.append([name, sanitized_func, sanitized_args, sanitized_kwargs])\n",
    "        return self\n",
    "#Sanitization\n",
    "    def sanitize(self, obj):\n",
    "        if hasattr(obj, \"__self__\"):\n",
    "            method_self = getattr(obj, \"__self__\")\n",
    "            for name,_,_,_ in self._var_pkl:\n",
    "                if getattr(self, name) is method_self:\n",
    "                    return _method_temp(name, obj.__name__)\n",
    "            for var in self._var:\n",
    "                if var is method_self:\n",
    "                    start = len(self._uuid)\n",
    "                    restart = var.name[start:].find('/') + start + 1\n",
    "                    return _method_temp(var.name[restart:var.name.rfind(\":\")], obj.__name__)\n",
    "        try:\n",
    "            pkl.dumps(obj)\n",
    "            return obj\n",
    "        except:\n",
    "            start = len(self._uuid)\n",
    "            restart = obj.name[start:].find('/') + start + 1\n",
    "            return _tf_temp(obj.name[restart:obj.name.rfind(\":\")])\n",
    "    def unsanitize(self, obj):\n",
    "        if isinstance(obj, _tf_temp):\n",
    "            try:\n",
    "                return tf.get_variable(obj.name)\n",
    "            except:\n",
    "                end = obj.name.find('/')\n",
    "                return getattr(self, obj.name[:end])\n",
    "        if isinstance(obj, _method_temp):\n",
    "            try:\n",
    "                return getattr(tf.get_variable(obj.name), obj.method_name)\n",
    "            except:\n",
    "                return getattr(getattr(self, obj.name), obj.method_name)\n",
    "        return obj\n",
    "#Features\n",
    "    def setFile(self, save_file_name):\n",
    "        self._file_name = save_file_name\n",
    "#Values\n",
    "    def save(self, save_file_name = None):\n",
    "        variables = []\n",
    "        start = len(self._uuid)\n",
    "        for i in self._vars:\n",
    "            restart = i.name[start:].find('/') + start + 1\n",
    "            if tf.is_variable_initialized(i).eval():\n",
    "                try:\n",
    "                    variables.append((i.name[restart:i.name.rfind(\":\")],i.value().eval()))\n",
    "                except:\n",
    "                    #TODO: Don't do this. Limit exceptions to known expected ones.\n",
    "                    pass\n",
    "        with open(self._file_name, \"wb\") as file:\n",
    "            pkl.dump(variables, file)\n",
    "    def load(self, save_file_name = None):\n",
    "        try:\n",
    "            with open(self._file_name, \"rb\") as file:\n",
    "                variables = pkl.load(file)\n",
    "            with tf.variable_scope(self._uuid, reuse=True):\n",
    "                for i in variables:\n",
    "                    tf.get_variable(i[0]).assign(i[1]).eval(session=self._sess)\n",
    "        except:\n",
    "            #TODO: Don't do this. Limit exceptions to known expected ones.\n",
    "            pass\n",
    "#Serialization\n",
    "    def __reduce__(self):\n",
    "        return (CruiseControl, (self._file_name,), self._var_pkl)\n",
    "    def __setstate__(self, state):\n",
    "        for i in state:\n",
    "            self.add(i[0],i[1],*i[2],**i[3])\n",
    "        return self\n",
    "    '''\n",
    "#Initialization\n",
    "    def initialize_variables(self, specifically=None):\n",
    "        uninitialized = []\n",
    "        start = len(self._uuid)\n",
    "        with tf.variable_scope(self._uuid, reuse=True):\n",
    "            for name in self._sess.run(tf.report_uninitialized_variables(self._vars)):\n",
    "                name = name.decode(\"utf-8\")\n",
    "                restart = name[start:].find('/') + start + 1\n",
    "                end = name.rfind(\":\")\n",
    "                if end == -1:\n",
    "                    end = None\n",
    "                print(name)\n",
    "                print(restart)\n",
    "                print(end)\n",
    "                print(name[restart:end])\n",
    "                uninitialized.append(tf.get_variable(name[restart:end]))\n",
    "        self._sess.run(tf.initialize_variables(uninitialized))\n",
    "    '''\n",
    "#Functionality\n",
    "    def __enter__(self):\n",
    "        self._sess = tf.Session()\n",
    "        #self.initialize_variables()\n",
    "        # trying to be smart about initialization seems\n",
    "        #  to be a bad idea for some reason?\n",
    "        self._sess.run(tf.initialize_all_variables())\n",
    "        # We're just going to load values back anyway.\n",
    "        self.load()\n",
    "        return self._sess.__enter__()\n",
    "    def __exit__(self, *args):\n",
    "        self.save()\n",
    "        return self._sess.__exit__(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def clu(x, outdim, indim=None):\n",
    "    if indim:\n",
    "        try:\n",
    "            indim = list(indim)\n",
    "        except:\n",
    "            indim = [indim]\n",
    "    else:\n",
    "        indim = x.get_shape()[1:].as_list()\n",
    "    try:\n",
    "        outdim = list(outdim)\n",
    "    except:\n",
    "        outdim = [outdim]\n",
    "    C = tf.get_variable(\"C\", initializer=tf.truncated_normal(indim+outdim, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.truncated_normal(outdim, stddev=0.1))\n",
    "    cluKernel = -tf.reduce_sum(tf.abs(tf.sub(tf.expand_dims(x,len(indim)+1),\n",
    "                                        tf.expand_dims(C,0))),\n",
    "                          1) + b\n",
    "    cluKernel._C = C\n",
    "    cluKernel._b = b\n",
    "    return cluKernel\n",
    "\n",
    "def lin(x, shape):\n",
    "    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.truncated_normal(shape[1:], stddev=0.1))\n",
    "    linKernel = tf.matmul(x,W) + b\n",
    "    linKernel._W = W\n",
    "    linKernel._b = b\n",
    "    return linKernel\n",
    "\n",
    "#Convolution and Maxpool shortcuts\n",
    "def conv2d(x, shape):\n",
    "    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.constant(0.1, shape=shape[-1:]))\n",
    "    convKernel = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "    convKernel._W = W\n",
    "    convKernel._b = b\n",
    "    return convKernel\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def cross_entropy(y,yhat):\n",
    "    return -tf.reduce_sum(y*tf.log(yhat + 1e-9)) #Without epsilon, it crashes.\n",
    "\n",
    "def accuracy_test(y,yhat):\n",
    "    correct_prediction = tf.equal(tf.argmax(yhat,1), tf.argmax(y,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<laminarflow._cruisecontrol.CruiseControl at 0x7fbcb0432d30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from laminarflow import CruiseControl\n",
    "\n",
    "test = CruiseControl(\"test\")\n",
    "test.add('input',tf.placeholder, \"float\", shape=[None, 784])\n",
    "#test.add('expected_output', tf.placeholder, \"float\", shape=[None, 10])\n",
    "test.add('h', lin, test.input,[784,10])\n",
    "test.add('output', tf.nn.softmax, test.h)\n",
    "#test.add('optim', tf.train.AdadeltaOptimizer, 1e-4)\n",
    "#test.add('loss', cross_entropy, test.expected_output, test.output)\n",
    "#test.add('train_step', test.optim.minimize, test.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.56635098e-04   9.22801197e-01   3.53984050e-02   5.09097939e-04\n",
      "    3.00782995e-04   1.29580693e-02   6.00280566e-03   7.86879566e-04\n",
      "    1.86771862e-02   1.80903543e-03]]\n",
      "[[  7.56635098e-04   9.22801197e-01   3.53984050e-02   5.09097939e-04\n",
      "    3.00782995e-04   1.29580693e-02   6.00280566e-03   7.86879566e-04\n",
      "    1.86771862e-02   1.80903543e-03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.56635098e-04   9.22801197e-01   3.53984050e-02   5.09097939e-04\n",
      "    3.00782995e-04   1.29580693e-02   6.00280566e-03   7.86879566e-04\n",
      "    1.86771862e-02   1.80903543e-03]]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "test2 = pkl.loads(pkl.dumps(test))\n",
    "with test2 as sess:\n",
    "    print(test2.output.eval({test2.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.56635098e-04   9.22801197e-01   3.53984050e-02   5.09097939e-04\n",
      "    3.00782995e-04   1.29580693e-02   6.00280566e-03   7.86879566e-04\n",
      "    1.86771862e-02   1.80903543e-03]]\n",
      "[[ 0.01438009  0.00087475  0.01885835  0.04185215  0.06387353  0.01450145\n",
      "   0.00137812  0.52542412  0.00159438  0.31726319]]\n"
     ]
    }
   ],
   "source": [
    "test = CruiseControl(\"test\")\n",
    "test.add('input',tf.placeholder, \"float\", shape=[None, 784])\n",
    "test.add('expected_output', tf.placeholder, \"float\", shape=[None, 10])\n",
    "test.add('h', lin, test.input,[784,10])\n",
    "test.add('output', tf.nn.softmax, test.h)\n",
    "test.add('optim', tf.train.AdadeltaOptimizer, 1e-4)\n",
    "test.add('loss', cross_entropy, test.expected_output, test.output)\n",
    "test.add('train_step', test.optim.minimize, test.loss)\n",
    "#testing\n",
    "test._initialized = set(x for x in test._vars)\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'minimize'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._var_pkl[6][1].method_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.37546110e-01   2.27814773e-03   9.26363617e-02   1.84260221e-04\n",
      "    2.06556288e-03   1.05861656e-03   4.58063696e-05   6.26441836e-02\n",
      "    1.17108016e-03   3.69892048e-04]]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "test2 = pkl.loads(pkl.dumps(test))\n",
    "with test2 as sess:\n",
    "    print(test2.output.eval({test2.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58142567  0.00060284  0.00336342  0.01735914  0.03144473  0.02135924\n",
      "   0.0277974   0.23094912  0.0768769   0.00882158]]\n",
      "[[ 0.09610475  0.11759425  0.08281995  0.09182145  0.08793612  0.12338841\n",
      "   0.10333482  0.07687112  0.08729345  0.13283578]]\n"
     ]
    }
   ],
   "source": [
    "test.add('relu', tf.nn.relu, test.h)\n",
    "test.add('h2', lin, test.relu, [10,10])\n",
    "test.add('output2', tf.nn.softmax, test.h2)\n",
    "test.add('loss2', cross_entropy, test.expected_output, test.output2)\n",
    "test.add('train_step2', test.optim.minimize, test.loss2)\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "with test as sess:\n",
    "    print(test.output2.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d253bd7304d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_variable_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "tf.is_variable_initialized(t).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"test2\"):\n",
    "    test = {}\n",
    "    test['in'] = tf.placeholder(\"float\", shape=[1,2])\n",
    "    test['out'] = tf.placeholder(\"float\", shape=[1,3])\n",
    "    test['W'] = tf.get_variable(\"W\", shape=[2,3])\n",
    "    test['loss'] = tf.nn.l2_loss(tf.matmul(test['in'], test['W']) - test['out'])\n",
    "    test['optim'] = tf.train.AdadeltaOptimizer()\n",
    "    test['train_step'] = test['optim'].minimize(test['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['train_step'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[i.name for i in tf.all_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "with tf.variable_scope(\"test2\", reuse=True):\n",
    "    W = tf.get_variable(\"W\")\n",
    "    #WAda = tf.get_variable(\"test2/W/Adadelta:0\")\n",
    "    WAda1 = tf.get_variable(\"test2/W/Adadelta_1:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
