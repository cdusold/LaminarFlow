{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting laminarflow/_cruisecontrol.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile laminarflow/_cruisecontrol.py\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "    \n",
    "class _tf_temp():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "class _method_temp():\n",
    "    def __init__(self, name, method_name):\n",
    "        self.name = name\n",
    "        self.method_name = method_name\n",
    "\n",
    "class CruiseControl():\n",
    "    \"\"\"\n",
    "    Laminar Flow's Cruise Control method automates several\n",
    "    time saving tasks for Tensorflow, allowing for quicker\n",
    "    prototyping and testing.\n",
    "    \n",
    "    Among these abilities is automatic saving in an encapsulated\n",
    "    tensorflow session. This makes it so you don't need to\n",
    "    keep open a session to keep the values. However, it does\n",
    "    require you to use `tf.get_variable` to define variables\n",
    "    instead of `tf.Variable` directly.\n",
    "    \n",
    "    On top of that, automatic initialization of uninitialized\n",
    "    variables allows for this structure to be dynamically updated\n",
    "    and have no cat and mouse hunt for errors.\n",
    "    \n",
    "    Pickling and unpickling has been implemented in this class\n",
    "    under the strict conditions that all non-variable tensors\n",
    "    used in args to the `add` function are the result of previous\n",
    "    functions input to the `add` function and all `function`s used\n",
    "    have to either be functions or methods bound to results of\n",
    "    previous calls to add. That is, when calling `add`, only use\n",
    "    direct attributes of that CruiseControl instance or variables\n",
    "    controlled by it and only use functions or methods controlled\n",
    "    by that instance as well.\n",
    "    \n",
    "    Since TensorFlow objects are not pickleable directly, args\n",
    "    and kwargs to `add` have to be easily sanitized, unless you\n",
    "    want to do it yourself. More complex sanitization is possible,\n",
    "    if somewhat difficult. To sanitize yourself, currently you must\n",
    "    create the magic functions in whatever you pass to `add` if\n",
    "    it isn't automatically taken care of already.\n",
    "    \n",
    "    More documentation to follow. This all needs to be reworded\n",
    "    to make more sense.\n",
    "    \"\"\"\n",
    "#Constructor\n",
    "    def __init__(self, save_file_name, unique_identifier = None):\n",
    "        #collect_variables()\n",
    "        self._vars = set()\n",
    "        self._var_pkl = list()\n",
    "        self._file_name = save_file_name\n",
    "        self.saver = None\n",
    "        self._uuid = unique_identifier if unique_identifier else hex(id(self))[2:]\n",
    "        try:\n",
    "            with tf.variable_scope(self._uuid):\n",
    "                with tf.variable_scope(self._uuid):\n",
    "                    tf.get_variable(\"initialized\",shape=[1])\n",
    "        except:\n",
    "            raise NameError(\"Error: {} is an invalid unique identifier.\".format(self._uuid))\n",
    "#Structure\n",
    "    def add(self, name, function, *args, **kwargs):\n",
    "        if hasattr(self, name):\n",
    "            raise AttributeError(\"Error: {} already defined.\".format(name))\n",
    "        current = set(tf.all_variables())\n",
    "        #sanitize\n",
    "        sanitized_args = [self.sanitize(arg) for arg in args]\n",
    "        sanitized_kwargs = {key:self.sanitize(value) for key,value in kwargs.items()}\n",
    "        sanitized_func = self.sanitize(function)\n",
    "        #Test.\n",
    "        try:\n",
    "            pkl.dumps([sanitized_func, sanitized_args, sanitized_kwargs])\n",
    "        except:\n",
    "            raise ValueError(\"Error: Unable to sanitize.\")\n",
    "        #unsanitize\n",
    "        unsanitized_func = self.unsanitize(function)\n",
    "        unsanitized_args = [self.unsanitize(arg) for arg in args]\n",
    "        unsanitized_kwargs = {key:self.unsanitize(value) for key,value in kwargs.items()}\n",
    "        with tf.variable_scope(self._uuid):\n",
    "            with tf.variable_scope(name):\n",
    "                setattr(self, name, unsanitized_func(*unsanitized_args, **unsanitized_kwargs))\n",
    "        self._vars |= set(tf.all_variables()) - current\n",
    "        self._var_pkl.append([name, sanitized_func, sanitized_args, sanitized_kwargs])\n",
    "        if isinstance(getattr(self, name), tf.train.Optimizer):\n",
    "            #Initialize slots?\n",
    "            pass\n",
    "        return self\n",
    "    def last_added(self):\n",
    "        try:\n",
    "            return getattr(self, self._var_pkl[-1][0])\n",
    "        except:\n",
    "            return None\n",
    "#Sanitization\n",
    "    def removeUUIDandColon(self, name):\n",
    "        #start = 3 #len(\"{0}\")\n",
    "        name = name[len(self._uuid):].replace(self._uuid, \"{0}\")\n",
    "        #restart = var.name[start:].find('/') + start + 1\n",
    "        #restart = name.find('/') + 1\n",
    "        #return name[restart:name.rfind(\":\")]\n",
    "        return name[name.find('/') + 1:name.rfind(\":\")]\n",
    "    def sanitize(self, obj):\n",
    "        if hasattr(obj, \"__self__\"):\n",
    "            method_self = getattr(obj, \"__self__\")\n",
    "            for name,_,_,_ in self._var_pkl:\n",
    "                if getattr(self, name) is method_self:\n",
    "                    return _method_temp(name, obj.__name__)\n",
    "            for var in self._var:\n",
    "                if var is method_self:\n",
    "                    return _method_temp(self.removeUUIDandColon(var.name), obj.__name__)\n",
    "        try:\n",
    "            pkl.dumps(obj)\n",
    "            return obj\n",
    "        except:\n",
    "            return _tf_temp(self.removeUUIDandColon(obj.name))\n",
    "    def unsanitize(self, obj):\n",
    "        if isinstance(obj, _tf_temp):\n",
    "            try:\n",
    "                return tf.get_variable(obj.name.format(self._uuid))\n",
    "            except:\n",
    "                end = obj.name.find('/')\n",
    "                return getattr(self, obj.name[:end])\n",
    "        if isinstance(obj, _method_temp):\n",
    "            try:\n",
    "                return getattr(tf.get_variable(obj.name.format(self._uuid)), obj.method_name)\n",
    "            except:\n",
    "                return getattr(getattr(self, obj.name.format(self._uuid)), obj.method_name)\n",
    "        return obj\n",
    "#Features\n",
    "    def setFile(self, save_file_name):\n",
    "        self._file_name = save_file_name\n",
    "#Values\n",
    "    def save(self, save_file_name = None):\n",
    "        variables = []\n",
    "        for i in self._vars:\n",
    "            if tf.is_variable_initialized(i).eval():\n",
    "                try:\n",
    "                    variables.append((self.removeUUIDandColon(i.name),i.value().eval()))\n",
    "                except:\n",
    "                    #TODO: Don't do this. Limit exceptions to known expected ones.\n",
    "                    pass\n",
    "        if save_file_name is None:\n",
    "            save_file_name = self._file_name\n",
    "        with open(self._file_name, \"wb\") as file:\n",
    "            pkl.dump(variables, file)\n",
    "    def load(self, save_file_name = None):\n",
    "        try:\n",
    "            if save_file_name is None:\n",
    "                save_file_name = self._file_name\n",
    "            with open(self._file_name, \"rb\") as file:\n",
    "                variables = pkl.load(file)\n",
    "        except:\n",
    "            #TODO: Don't do this. Limit exceptions to known expected ones.\n",
    "            return\n",
    "        with tf.variable_scope(self._uuid, reuse=True):\n",
    "            for i in variables:\n",
    "                try:\n",
    "                    tf.get_variable(i[0].format(self._uuid)).assign(i[1]).eval(session=self._sess)\n",
    "                except ValueError as msg:\n",
    "                    #print(str(msg))\n",
    "                    pass\n",
    "    def transfer_from(self, save_file_name):\n",
    "        self.load(save_file_name)\n",
    "        #yes, this is just an alias for readability sake, and to force a file name.\n",
    "        \n",
    "#Serialization\n",
    "    def __reduce__(self):\n",
    "        return (CruiseControl, (self._file_name,), self._var_pkl)\n",
    "    def __setstate__(self, state):\n",
    "        for i in state:\n",
    "            self.add(i[0],i[1],*i[2],**i[3])\n",
    "        return self\n",
    "    '''\n",
    "#Initialization\n",
    "    def initialize_variables(self, specifically=None):\n",
    "        uninitialized = []\n",
    "        start = len(self._uuid)\n",
    "        with tf.variable_scope(self._uuid, reuse=True):\n",
    "            for name in self._sess.run(tf.report_uninitialized_variables(self._vars)):\n",
    "                name = name.decode(\"utf-8\")\n",
    "                restart = name[start:].find('/') + start + 1\n",
    "                end = name.rfind(\":\")\n",
    "                if end == -1:\n",
    "                    end = None\n",
    "                print(name)\n",
    "                print(restart)\n",
    "                print(end)\n",
    "                print(name[restart:end])\n",
    "                uninitialized.append(tf.get_variable(name[restart:end]))\n",
    "        self._sess.run(tf.initialize_variables(uninitialized))\n",
    "    '''\n",
    "#Functionality\n",
    "    def __enter__(self):\n",
    "        self._sess = tf.Session()\n",
    "        #self.initialize_variables()\n",
    "        # trying to be smart about initialization seems\n",
    "        #  to be a bad idea for some reason?\n",
    "        self._sess.run(tf.initialize_all_variables())\n",
    "        # We're just going to load values back anyway.\n",
    "        self.load()\n",
    "        return self._sess.__enter__()\n",
    "    def __exit__(self, *args):\n",
    "        self.save()\n",
    "        return self._sess.__exit__(*args)\n",
    "    def run(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        This provides Session.run access to the CruiseControlled sesion.\n",
    "        \"\"\"\n",
    "        with self:\n",
    "            return self._sess.run(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def clu(x, outdim, indim=None):\n",
    "    if indim:\n",
    "        try:\n",
    "            indim = list(indim)\n",
    "        except:\n",
    "            indim = [indim]\n",
    "    else:\n",
    "        indim = x.get_shape()[1:].as_list()\n",
    "    try:\n",
    "        outdim = list(outdim)\n",
    "    except:\n",
    "        outdim = [outdim]\n",
    "    C = tf.get_variable(\"C\", initializer=tf.truncated_normal(indim+outdim, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.truncated_normal(outdim, stddev=0.1))\n",
    "    cluKernel = -tf.reduce_sum(tf.abs(tf.sub(tf.expand_dims(x,len(indim)+1),\n",
    "                                        tf.expand_dims(C,0))),\n",
    "                          1) + b\n",
    "    cluKernel._C = C\n",
    "    cluKernel._b = b\n",
    "    return cluKernel\n",
    "\n",
    "def lin(x, shape):\n",
    "    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.truncated_normal(shape[1:], stddev=0.1))\n",
    "    linKernel = tf.matmul(x,W) + b\n",
    "    linKernel._W = W\n",
    "    linKernel._b = b\n",
    "    return linKernel\n",
    "\n",
    "#Convolution and Maxpool shortcuts\n",
    "def conv2d(x, shape):\n",
    "    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.constant(0.1, shape=shape[-1:]))\n",
    "    convKernel = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "    convKernel._W = W\n",
    "    convKernel._b = b\n",
    "    return convKernel\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def cross_entropy(y,yhat):\n",
    "    return -tf.reduce_sum(y*tf.log(yhat + 1e-9)) #Without epsilon, it crashes.\n",
    "\n",
    "def accuracy_test(y,yhat):\n",
    "    correct_prediction = tf.equal(tf.argmax(yhat,1), tf.argmax(y,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<laminarflow._cruisecontrol.CruiseControl at 0x7f9d3b642ef0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from laminarflow import CruiseControl\n",
    "\n",
    "test = CruiseControl(\"test\")\n",
    "test.add('input',tf.placeholder, \"float\", shape=[None, 784])\n",
    "#test.add('expected_output', tf.placeholder, \"float\", shape=[None, 10])\n",
    "test.add('h', lin, test.input,[784,10])\n",
    "test.add('output', tf.nn.softmax, test.h)\n",
    "#test.add('optim', tf.train.AdadeltaOptimizer, 1e-4)\n",
    "#test.add('loss', cross_entropy, test.expected_output, test.output)\n",
    "#test.add('train_step', test.optim.minimize, test.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01209501  0.09254285  0.44434726  0.06741246  0.00355368  0.02373637\n",
      "   0.04553262  0.01821334  0.21290119  0.07966527]]\n",
      "[[ 0.01209501  0.09254285  0.44434726  0.06741246  0.00355368  0.02373637\n",
      "   0.04553262  0.01821334  0.21290119  0.07966527]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01209501  0.09254285  0.44434726  0.06741246  0.00355368  0.02373637\n",
      "   0.04553262  0.01821334  0.21290119  0.07966527]]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "test2 = pkl.loads(pkl.dumps(test))\n",
    "with test2 as sess:\n",
    "    print(test2.output.eval({test2.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01209501  0.09254285  0.44434726  0.06741246  0.00355368  0.02373637\n",
      "   0.04553262  0.01821334  0.21290119  0.07966527]]\n",
      "[[ 0.01209501  0.09254285  0.44434726  0.06741246  0.00355368  0.02373637\n",
      "   0.04553262  0.01821334  0.21290119  0.07966527]]\n"
     ]
    }
   ],
   "source": [
    "test = CruiseControl(\"test\")\n",
    "test.add('input',tf.placeholder, \"float\", shape=[None, 784])\n",
    "test.add('expected_output', tf.placeholder, \"float\", shape=[None, 10])\n",
    "test.add('h', lin, test.input,[784,10])\n",
    "test.add('output', tf.nn.softmax, test.h)\n",
    "test.add('optim', tf.train.AdadeltaOptimizer, 1e-4)\n",
    "test.add('loss', cross_entropy, test.expected_output, test.output)\n",
    "test.add('train_step', test.optim.minimize, test.loss)\n",
    "#testing\n",
    "test._initialized = set(x for x in test._vars)\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "print(test.run(test.output,feed_dict={test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.variables.Variable object at 0x7f9d3b642c50>\n"
     ]
    }
   ],
   "source": [
    "print(test.optim._zeros_slot(test.loss, 'accum_update', test.optim._name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7f9d180739b0_6/loss/Neg/Adadelta:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.optim.get_slot(test.loss, 'accum_update').name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7f9d3b642ef0/7f9d3b642ef0/initialized:0', '7f9d3b642ef0/h/W:0', '7f9d3b642ef0/h/b:0', '7f9d3b642be0/7f9d3b642be0/initialized:0', '7f9d3b642be0/h/W:0', '7f9d3b642be0/h/b:0', '7f9d180739b0/7f9d180739b0/initialized:0', '7f9d180739b0/h/W:0', '7f9d180739b0/h/b:0']\n"
     ]
    }
   ],
   "source": [
    "print([i.name for i in tf.trainable_variables()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'minimize'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._var_pkl[6][1].method_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01209501  0.09254285  0.44434726  0.06741246  0.00355368  0.02373637\n",
      "   0.04553262  0.01821334  0.21290119  0.07966527]]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "test2 = pkl.loads(pkl.dumps(test))\n",
    "with test2 as sess:\n",
    "    print(test2.output.eval({test2.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01209501  0.09254285  0.44434726  0.06741246  0.00355368  0.02373637\n",
      "   0.04553262  0.01821334  0.21290119  0.07966527]]\n",
      "[[ 0.12342255  0.10235687  0.08753664  0.07419886  0.07023831  0.11619722\n",
      "   0.11196873  0.09138086  0.10553516  0.11716482]]\n"
     ]
    }
   ],
   "source": [
    "test.add('relu', tf.nn.relu, test.h)\n",
    "test.add('h2', lin, test.relu, [10,10])\n",
    "test.add('output2', tf.nn.softmax, test.h2)\n",
    "test.add('loss2', cross_entropy, test.expected_output, test.output2)\n",
    "test.add('train_step2', test.optim.minimize, test.loss2)\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "with test as sess:\n",
    "    print(test.output2.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AdadeltaOptimizer' object has no attribute '_get_or_create_slot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f195d529777b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_or_create_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'accum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'AdadeltaOptimizer' object has no attribute '_get_or_create_slot'"
     ]
    }
   ],
   "source": [
    "test.optim._get_or_create_slot(test.loss2,'accum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.is_variable_initialized(t).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"test2\"):\n",
    "    test = {}\n",
    "    test['in'] = tf.placeholder(\"float\", shape=[1,2])\n",
    "    test['out'] = tf.placeholder(\"float\", shape=[1,3])\n",
    "    test['W'] = tf.get_variable(\"W\", shape=[2,3])\n",
    "    test['loss'] = tf.nn.l2_loss(tf.matmul(test['in'], test['W']) - test['out'])\n",
    "    test['optim'] = tf.train.AdadeltaOptimizer()\n",
    "    test['train_step'] = test['optim'].minimize(test['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['train_step'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[i.name for i in tf.all_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "with tf.variable_scope(\"test2\", reuse=True):\n",
    "    W = tf.get_variable(\"W\")\n",
    "    #WAda = tf.get_variable(\"test2/W/Adadelta:0\")\n",
    "    WAda1 = tf.get_variable(\"test2/W/Adadelta_1:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"{0} is {0}\".format(\"this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(\"{0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.loss._shape_as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(test.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(dir(test.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in test.output.op.inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir(test.output.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.output.graph.get_tensor_by_name(test.input.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.output.graph.is_feedable(test.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[i.name for i in test._vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.is_variable_initialized(test.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test._sess.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sess:\n",
    "    test.expected_output.eval(feed_dict={test.expected_output:np.ones([1,10])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.Graph().get_tensor_by_name(test.input.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(test.h.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.unique_name(test.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
