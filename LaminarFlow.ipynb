{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting LaminarFlow/LaminarFlow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile LaminarFlow/LaminarFlow.py\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "    \n",
    "class _tf_temp():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "class CruiseControl():\n",
    "    \"\"\"\n",
    "    Laminar Flow's Cruise Control method automates several\n",
    "    time saving tasks for Tensorflow, allowing for quicker\n",
    "    prototyping and testing.\n",
    "    \n",
    "    Among these abilities is automatic saving in an encapsulated\n",
    "    tensorflow session. This makes it so you don't need to\n",
    "    keep open a session to keep the values. However, it does\n",
    "    require you to use `tf.get_variable` to define variables\n",
    "    instead of `tf.Variable` directly.\n",
    "    \n",
    "    On top of that, automatic initialization of uninitialized\n",
    "    variables allows for this structure to be dynamically updated\n",
    "    and have no cat and mouse hunt for errors.\n",
    "    \n",
    "    Pickling and unpickling has been implemented in this class\n",
    "    under the strict condition that all non-variable tensors\n",
    "    used in args to the `add` function are the result of previous\n",
    "    functions input to the `add` function. That is, when calling\n",
    "    `add`, only use direct attributes of that CruiseControl\n",
    "    instance or variables controlled by it.\n",
    "    \n",
    "    More documentation to follow.\n",
    "    \"\"\"\n",
    "#Constructor\n",
    "    def __init__(self, save_file_name, unique_identifier = None):\n",
    "        #collect_variables()\n",
    "        self._vars = set()\n",
    "        self._initialized = set()\n",
    "        self._var_pkl = list()\n",
    "        self._file_name = save_file_name\n",
    "        self.saver = None\n",
    "        self._uuid = unique_identifier if unique_identifier else hex(id(self))[2:]\n",
    "        try:\n",
    "            with tf.variable_scope(self._uuid):\n",
    "                with tf.variable_scope(self._uuid):\n",
    "                    tf.get_variable(\"initialized\",shape=[1])\n",
    "        except:\n",
    "            raise NameError(\"Error: {} is an invalid unique identifier.\".format(self._uuid))\n",
    "#Structure\n",
    "    def add(self, name, function, *args, **kwargs):\n",
    "        if hasattr(self, name):\n",
    "            raise AttributeError(\"Error: {} already defined.\".format(name))\n",
    "        current = set(tf.all_variables())\n",
    "        #sanitize\n",
    "        sanitized_args = []\n",
    "        start = len(self._uuid)\n",
    "        for i in args:\n",
    "            try:\n",
    "                pkl.dumps(i)\n",
    "                sanitized_args.append(i)\n",
    "            except:\n",
    "                restart = i.name[start:].find('/') + start + 1\n",
    "                sanitized_args.append(_tf_temp(i.name[restart:i.name.rfind(\":\")]))\n",
    "        #Test keyword args.\n",
    "        try:\n",
    "            pkl.dumps(kwargs)\n",
    "        except:\n",
    "            raise ValueError(\"Error: Unable to handle tf objects in keyword args currently.\")\n",
    "        with tf.variable_scope(self._uuid):\n",
    "            #unsanitize\n",
    "            unsanitized_args = []\n",
    "            for i in args:\n",
    "                if isinstance(i, _tf_temp):\n",
    "                    try:\n",
    "                        unsanitized_args.append(tf.get_variable(i.name))\n",
    "                    except:\n",
    "                        end = i.name.find('/')\n",
    "                        unsanitized_args.append(getattr(self, i.name[:end]))\n",
    "                else:\n",
    "                    unsanitized_args.append(i)\n",
    "            with tf.variable_scope(name):\n",
    "                setattr(self, name, function(*unsanitized_args, **kwargs))\n",
    "        self._vars |= set(tf.all_variables()) - current\n",
    "        self._var_pkl.append([name, function, sanitized_args, kwargs])\n",
    "        return self\n",
    "#Features\n",
    "    def setFile(self, save_file_name):\n",
    "        self._file_name = save_file_name\n",
    "#Values\n",
    "    def save(self, save_file_name = None):\n",
    "        variables = []\n",
    "        start = len(self._uuid)\n",
    "        for i in self._vars:\n",
    "            restart = i.name[start:].find('/') + start + 1\n",
    "            if tf.is_variable_initialized(i).eval():\n",
    "                try:\n",
    "                    variables.append((i.name[restart:i.name.rfind(\":\")],i.value().eval()))\n",
    "                except:\n",
    "                    #TODO: Don't do this.\n",
    "                    pass\n",
    "        with open(self._file_name, \"wb\") as file:\n",
    "            pkl.dump(variables, file)\n",
    "    def load(self, save_file_name = None):\n",
    "        try:\n",
    "            with open(self._file_name, \"rb\") as file:\n",
    "                variables = pkl.load(file)\n",
    "            with tf.variable_scope(self._uuid, reuse=True):\n",
    "                for i in variables:\n",
    "                    tf.get_variable(i[0]).assign(i[1]).eval(session=self._sess)\n",
    "        except:\n",
    "            pass\n",
    "#Serialization\n",
    "    def __reduce__(self):\n",
    "        return (CruiseControl, (self._file_name,), self._var_pkl)\n",
    "    def __setstate__(self, state):\n",
    "        for i in state:\n",
    "            self.add(i[0],i[1],*i[2],**i[3])\n",
    "        return self\n",
    "#Functionality\n",
    "    def __enter__(self):\n",
    "        self._sess = tf.Session()\n",
    "        uninitialized = self._vars - self._initialized\n",
    "        # Fixed in TF 0.9. Upgrade now!\n",
    "        #uninitialized = tf.report_uninitialized_variables(self._vars).eval(session=self._sess)\n",
    "        self._sess.run(tf.initialize_variables(list(uninitialized)))\n",
    "        self.load()\n",
    "        self._initialized = set(x for x in self._vars)\n",
    "        return self._sess.__enter__()\n",
    "    def __exit__(self, *args):\n",
    "        self.save()\n",
    "        return self._sess.__exit__(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def clu(x, outdim, indim=None):\n",
    "    if indim:\n",
    "        try:\n",
    "            indim = list(indim)\n",
    "        except:\n",
    "            indim = [indim]\n",
    "    else:\n",
    "        indim = x.get_shape()[1:].as_list()\n",
    "    try:\n",
    "        outdim = list(outdim)\n",
    "    except:\n",
    "        outdim = [outdim]\n",
    "    C = tf.get_variable(\"C\", initializer=tf.truncated_normal(indim+outdim, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.truncated_normal(outdim, stddev=0.1))\n",
    "    cluKernel = -tf.reduce_sum(tf.abs(tf.sub(tf.expand_dims(x,len(indim)+1),\n",
    "                                        tf.expand_dims(C,0))),\n",
    "                          1) + b\n",
    "    cluKernel._C = C\n",
    "    cluKernel._b = b\n",
    "    return cluKernel\n",
    "\n",
    "def lin(x, shape):\n",
    "    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.truncated_normal(shape[1:], stddev=0.1))\n",
    "    linKernel = tf.matmul(x,W) + b\n",
    "    linKernel._W = W\n",
    "    linKernel._b = b\n",
    "    return linKernel\n",
    "\n",
    "#Convolution and Maxpool shortcuts\n",
    "def conv2d(x, shape):\n",
    "    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.constant(0.1, shape=shape[-1:]))\n",
    "    convKernel = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "    convKernel._W = W\n",
    "    convKernel._b = b\n",
    "    return convKernel\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def cross_entropy(y,yhat):\n",
    "    return -tf.reduce_sum(y*tf.log(yhat + 1e-9)) #Without epsilon, it crashes.\n",
    "\n",
    "def accuracy_test(y,yhat):\n",
    "    correct_prediction = tf.equal(tf.argmax(yhat,1), tf.argmax(y,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LaminarFlow.CruiseControl at 0x7f1b2a8d1b38>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LaminarFlow import CruiseControl\n",
    "\n",
    "test = CruiseControl(\"test\")\n",
    "test.add('input',tf.placeholder, \"float\", shape=[None, 784])\n",
    "#test.add('expected_output', tf.placeholder, \"float\", shape=[None, 10])\n",
    "test.add('h', lin, test.input,[784,10])\n",
    "test.add('output', tf.nn.softmax, test.h)\n",
    "#test.add('optim', tf.train.AdadeltaOptimizer, 1e-4)\n",
    "#test.add('loss', cross_entropy, test.expected_output, test.output)\n",
    "#test.add('train_step', test.optim.minimize, test.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00099203  0.20124029  0.01566002  0.00757608  0.06891601  0.00304694\n",
      "   0.00833866  0.68667036  0.00223492  0.00532476]]\n",
      "[[ 0.00099203  0.20124029  0.01566002  0.00757608  0.06891601  0.00304694\n",
      "   0.00833866  0.68667036  0.00223492  0.00532476]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00099203  0.20124029  0.01566002  0.00757608  0.06891601  0.00304694\n",
      "   0.00833866  0.68667036  0.00223492  0.00532476]]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "test2 = pkl.loads(pkl.dumps(test))\n",
    "with test2 as sess:\n",
    "    print(test2.output.eval({test2.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00099203  0.20124029  0.01566002  0.00757608  0.06891601  0.00304694\n",
      "   0.00833866  0.68667036  0.00223492  0.00532476]]\n"
     ]
    }
   ],
   "source": [
    "test = CruiseControl(\"test\")\n",
    "test.add('input',tf.placeholder, \"float\", shape=[None, 784])\n",
    "test.add('expected_output', tf.placeholder, \"float\", shape=[None, 10])\n",
    "test.add('h', lin, test.input,[784,10])\n",
    "test.add('output', tf.nn.softmax, test.h)\n",
    "test.add('optim', tf.train.AdadeltaOptimizer, 1e-4)\n",
    "test.add('loss', cross_entropy, test.expected_output, test.output)\n",
    "test.add('train_step', test.optim.minimize, test.loss)\n",
    "#testing\n",
    "test._initialized = set(x for x in test._vars)\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00099203  0.20124029  0.01566002  0.00757608  0.06891601  0.00304694\n",
      "   0.00833866  0.68667036  0.00223492  0.00532476]]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value 7f1afc141588/h/W\n\t [[Node: 7f1afc141588/h/W/read = Identity[T=DT_FLOAT, _class=[\"loc:@7f1afc141588/h/W\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](7f1afc141588/h/W)]]\nCaused by op '7f1afc141588/h/W/read', defined at:\n  File \"/usr/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.4/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ac4228024192>\", line 4, in <module>\n    test.add('h', lin, test.input,[784,10])\n  File \"/home/poik/Dropbox/TensorFlowCruiseControl/LaminarFlow.py\", line 81, in add\n    setattr(self, name, function(*unsanitized_args, **kwargs))\n  File \"<ipython-input-2-a52849383550>\", line 25, in lin\n    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variable_scope.py\", line 339, in get_variable\n    collections=collections)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variable_scope.py\", line 262, in get_variable\n    collections=collections, caching_device=caching_device)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variable_scope.py\", line 158, in get_variable\n    dtype=variable_dtype)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variables.py\", line 209, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variables.py\", line 318, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 609, in identity\n    return _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStatusNotOK\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m--> 628\u001b[1;33m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStatusNotOK\u001b[0m: Failed precondition: Attempting to use uninitialized value 7f1afc141588/h/W\n\t [[Node: 7f1afc141588/h/W/read = Identity[T=DT_FLOAT, _class=[\"loc:@7f1afc141588/h/W\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](7f1afc141588/h/W)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-89c43210b6e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \"\"\"\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3332\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3333\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3334\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 340\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 564\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 637\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m       raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[1;32m--> 659\u001b[1;33m                                             e.code)\n\u001b[0m\u001b[0;32m    660\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value 7f1afc141588/h/W\n\t [[Node: 7f1afc141588/h/W/read = Identity[T=DT_FLOAT, _class=[\"loc:@7f1afc141588/h/W\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](7f1afc141588/h/W)]]\nCaused by op '7f1afc141588/h/W/read', defined at:\n  File \"/usr/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.4/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ac4228024192>\", line 4, in <module>\n    test.add('h', lin, test.input,[784,10])\n  File \"/home/poik/Dropbox/TensorFlowCruiseControl/LaminarFlow.py\", line 81, in add\n    setattr(self, name, function(*unsanitized_args, **kwargs))\n  File \"<ipython-input-2-a52849383550>\", line 25, in lin\n    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variable_scope.py\", line 339, in get_variable\n    collections=collections)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variable_scope.py\", line 262, in get_variable\n    collections=collections, caching_device=caching_device)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variable_scope.py\", line 158, in get_variable\n    dtype=variable_dtype)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variables.py\", line 209, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/variables.py\", line 318, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 609, in identity\n    return _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "test.add('relu', tf.nn.relu, test.h)\n",
    "test.add('h2', lin, test.relu, [10,10])\n",
    "test.add('output2', tf.nn.softmax, test.h2)\n",
    "test.add('loss2', cross_entropy, test.expected_output, test.output2)\n",
    "test.add('train_step2', test.optim.minimize, test.loss2)\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "with test as sess:\n",
    "    print(test.output2.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.is_variable_initialized(t).eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
