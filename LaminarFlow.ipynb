{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting laminarflow/_cruisecontrol.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile laminarflow/_cruisecontrol.py\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "    \n",
    "class _tf_temp():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "class _method_temp():\n",
    "    def __init__(self, name, method_name):\n",
    "        self.name = name\n",
    "        self.method_name = method_name\n",
    "\n",
    "class CruiseControl():\n",
    "    \"\"\"\n",
    "    Laminar Flow's Cruise Control method automates several\n",
    "    time saving tasks for Tensorflow, allowing for quicker\n",
    "    prototyping and testing.\n",
    "    \n",
    "    Among these abilities is automatic saving in an encapsulated\n",
    "    tensorflow session. This makes it so you don't need to\n",
    "    keep open a session to keep the values. However, it does\n",
    "    require you to use `tf.get_variable` to define variables\n",
    "    instead of `tf.Variable` directly.\n",
    "    \n",
    "    On top of that, automatic initialization of uninitialized\n",
    "    variables allows for this structure to be dynamically updated\n",
    "    and have no cat and mouse hunt for errors.\n",
    "    \n",
    "    Pickling and unpickling has been implemented in this class\n",
    "    under the strict conditions that all non-variable tensors\n",
    "    used in args to the `add` function are the result of previous\n",
    "    functions input to the `add` function and all `function`s used\n",
    "    have to either be functions or methods bound to results of\n",
    "    previous calls to add. That is, when calling `add`, only use\n",
    "    direct attributes of that CruiseControl instance or variables\n",
    "    controlled by it and only use functions or methods controlled\n",
    "    by that instance as well.\n",
    "    \n",
    "    Since TensorFlow objects are not pickleable directly, args\n",
    "    and kwargs to `add` have to be easily sanitized, unless you\n",
    "    want to do it yourself. More complex sanitization is possible,\n",
    "    if somewhat difficult. To sanitize yourself, currently you must\n",
    "    create the magic functions in whatever you pass to `add` if\n",
    "    it isn't automatically taken care of already.\n",
    "    \n",
    "    More documentation to follow. This all needs to be reworded\n",
    "    to make more sense.\n",
    "    \"\"\"\n",
    "#Constructor\n",
    "    def __init__(self, save_file_name, unique_identifier = None):\n",
    "        #collect_variables()\n",
    "        self._vars = set()\n",
    "        self._var_pkl = list()\n",
    "        self._file_name = save_file_name\n",
    "        self._uuid = unique_identifier if unique_identifier else hex(id(self))[2:]\n",
    "        self._g = tf.Graph()\n",
    "        with self._g.as_default():\n",
    "            while True:\n",
    "                try:\n",
    "                    with tf.variable_scope(self._uuid):\n",
    "                        with tf.variable_scope(self._uuid):\n",
    "                            tf.get_variable(\"initialized\",shape=[1])\n",
    "                    break\n",
    "                except:\n",
    "                    if unique_identifier is not None:\n",
    "                        raise NameError(\"Error: {} is an invalid unique identifier.\".format(self._uuid))\n",
    "                    self._uuid += \"0\"\n",
    "        self._sess = None\n",
    "        self._opened = 0\n",
    "#Structure\n",
    "    def add(self, name, function, *args, **kwargs):\n",
    "        self._sess = None\n",
    "        if hasattr(self, name):\n",
    "            raise AttributeError(\"Error: {} already defined.\".format(name))\n",
    "        current = set(self._g.get_collection(\"variables\"))\n",
    "        #sanitize\n",
    "        sanitized_args = [self.sanitize(arg) for arg in args]\n",
    "        sanitized_kwargs = {key:self.sanitize(value) for key,value in kwargs.items()}\n",
    "        sanitized_func = self.sanitize(function)\n",
    "        #Test.\n",
    "        try:\n",
    "            pkl.dumps([sanitized_func, sanitized_args, sanitized_kwargs])\n",
    "        except:\n",
    "            raise ValueError(\"Error: Unable to sanitize.\")\n",
    "        #unsanitize\n",
    "        unsanitized_func = self.unsanitize(function)\n",
    "        unsanitized_args = [self.unsanitize(arg) for arg in args]\n",
    "        unsanitized_kwargs = {key:self.unsanitize(value) for key,value in kwargs.items()}\n",
    "        with self._g.as_default():\n",
    "            with tf.variable_scope(self._uuid):\n",
    "                with tf.variable_scope(name):\n",
    "                    setattr(self, name, unsanitized_func(*unsanitized_args, **unsanitized_kwargs))\n",
    "        self._vars |= set(self._g.get_collection(\"variables\")) - current\n",
    "        self._var_pkl.append([name, sanitized_func, sanitized_args, sanitized_kwargs])\n",
    "        if isinstance(getattr(self, name), tf.train.Optimizer):\n",
    "            #Initialize slots?\n",
    "            pass\n",
    "        return self\n",
    "    def last_added(self):\n",
    "        try:\n",
    "            return getattr(self, self._var_pkl[-1][0])\n",
    "        except:\n",
    "            return None\n",
    "#Sanitization\n",
    "    def removeUUIDandColon(self, name):\n",
    "        #start = 3 #len(\"{0}\")\n",
    "        name = name[len(self._uuid):].replace(self._uuid, \"{0}\")\n",
    "        #restart = var.name[start:].find('/') + start + 1\n",
    "        #restart = name.find('/') + 1\n",
    "        #return name[restart:name.rfind(\":\")]\n",
    "        return name[name.find('/') + 1:name.rfind(\":\")]\n",
    "    def sanitize(self, obj):\n",
    "        if hasattr(obj, \"__self__\"):\n",
    "            method_self = getattr(obj, \"__self__\")\n",
    "            for name,_,_,_ in self._var_pkl:\n",
    "                if getattr(self, name) is method_self:\n",
    "                    return _method_temp(name, obj.__name__)\n",
    "            for var in self._var:\n",
    "                if var is method_self:\n",
    "                    return _method_temp(self.removeUUIDandColon(var.name), obj.__name__)\n",
    "        try:\n",
    "            pkl.dumps(obj)\n",
    "            return obj\n",
    "        except:\n",
    "            return _tf_temp(self.removeUUIDandColon(obj.name))\n",
    "    def unsanitize(self, obj):\n",
    "        if isinstance(obj, _tf_temp):\n",
    "            try:\n",
    "                return tf.get_variable(obj.name.format(self._uuid))\n",
    "            except:\n",
    "                end = obj.name.find('/')\n",
    "                return getattr(self, obj.name[:end])\n",
    "        if isinstance(obj, _method_temp):\n",
    "            try:\n",
    "                return getattr(tf.get_variable(obj.name.format(self._uuid)), obj.method_name)\n",
    "            except:\n",
    "                return getattr(getattr(self, obj.name.format(self._uuid)), obj.method_name)\n",
    "        return obj\n",
    "#Features\n",
    "    def set_file(self, save_file_name):\n",
    "        self._file_name = save_file_name\n",
    "    setFile = set_file\n",
    "#Values\n",
    "    def save(self, save_file_name = None):\n",
    "        variables = []\n",
    "        for i in self._vars:\n",
    "            if tf.is_variable_initialized(i).eval():\n",
    "                try:\n",
    "                    variables.append((self.removeUUIDandColon(i.name),i.value().eval()))\n",
    "                except:\n",
    "                    #TODO: Don't do this. Limit exceptions to known expected ones.\n",
    "                    pass\n",
    "        if save_file_name is None:\n",
    "            save_file_name = self._file_name\n",
    "        with open(self._file_name, \"wb\") as file:\n",
    "            pkl.dump(variables, file)\n",
    "    def load(self, save_file_name = None):\n",
    "        \"\"\"\n",
    "        Must be done from within a with block.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if save_file_name is None:\n",
    "                save_file_name = self._file_name\n",
    "            with open(self._file_name, \"rb\") as file:\n",
    "                variables = pkl.load(file)\n",
    "        except:\n",
    "            #TODO: Don't do this. Limit exceptions to known expected ones.\n",
    "            #print(\"Unable to load pkl file.\")\n",
    "            return\n",
    "        with tf.variable_scope(self._uuid, reuse=True):\n",
    "            for i in variables:\n",
    "                try:\n",
    "                    tf.get_variable(i[0].format(self._uuid)).assign(i[1]).eval(session=self._sess)\n",
    "                except ValueError as msg:\n",
    "                    #print(str(msg))\n",
    "                    pass\n",
    "    def transfer_from(self, save_file_name):\n",
    "        self.load(save_file_name)\n",
    "        #yes, this is just an alias for readability sake, and to force a file name.\n",
    "#Serialization\n",
    "    def __reduce__(self):\n",
    "        return (CruiseControl, (self._file_name,), self._var_pkl)\n",
    "    def __setstate__(self, state):\n",
    "        for i in state:\n",
    "            self.add(i[0],i[1],*i[2],**i[3])\n",
    "        return self\n",
    "    '''\n",
    "#Initialization\n",
    "    def initialize_variables(self, specifically=None):\n",
    "        uninitialized = []\n",
    "        start = len(self._uuid)\n",
    "        with tf.variable_scope(self._uuid, reuse=True):\n",
    "            for name in self._sess.run(tf.report_uninitialized_variables(self._vars)):\n",
    "                name = name.decode(\"utf-8\")\n",
    "                restart = name[start:].find('/') + start + 1\n",
    "                end = name.rfind(\":\")\n",
    "                if end == -1:\n",
    "                    end = None\n",
    "                print(name)\n",
    "                print(restart)\n",
    "                print(end)\n",
    "                print(name[restart:end])\n",
    "                uninitialized.append(tf.get_variable(name[restart:end]))\n",
    "        self._sess.run(tf.initialize_variables(uninitialized))\n",
    "    '''\n",
    "#Functionality\n",
    "    @property\n",
    "    def sess(self):\n",
    "        if self._opened:\n",
    "            return self._sess\n",
    "        with self._g.as_default():\n",
    "            self._init = tf.global_variables_initializer()\n",
    "        self._sess = tf.Session(graph=self._g)\n",
    "        return self._sess\n",
    "    def __enter__(self):\n",
    "        sess = self.sess\n",
    "        self._opened += 1\n",
    "        if self._opened == 1:\n",
    "            sess.__enter__()\n",
    "            #self.initialize_variables()\n",
    "            # trying to be smart about initialization seems\n",
    "            #  to be a bad idea for some reason?\n",
    "            self._sess.run(self._init)\n",
    "            # We're just going to load values back anyway.\n",
    "            self.load()\n",
    "            return self\n",
    "        else:\n",
    "            return self\n",
    "    def __exit__(self, *args):\n",
    "        self.save()\n",
    "        self._opened -= 1\n",
    "        if self._opened == 0:\n",
    "            return self._sess.__exit__(*args)\n",
    "    def run(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        This provides Session.run access to the CruiseControlled sesion.\n",
    "        \"\"\"\n",
    "        with self:\n",
    "            return self._sess.run(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting laminarflow/_filedescriptors.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile laminarflow/_filedescriptors.py\n",
    "from laminarflow import CruiseControl\n",
    "\n",
    "# These will basically just read the file as said type,\n",
    "#  and the result will be dictlike already, so we can\n",
    "#  just pass it in appropriately.\n",
    "\n",
    "layer_types = {}\n",
    "\n",
    "def loadDictlike(dct):\n",
    "    \"\"\"\n",
    "    Given a network description as a list of dictionaries,\n",
    "    constructs a CruiseControl wrapped network with the\n",
    "    given definition.\n",
    "    \n",
    "    The values are translated using function pointers in\n",
    "    layer_types, which can be modified directly to give\n",
    "    new layer support. Helper functions will be provided\n",
    "    in future versions to speed up the process.\n",
    "    \n",
    "    The naming scheme of layers and description parameters\n",
    "    is inspired by Caffe's prototxt files in hopes of being\n",
    "    able to directly load Caffe's Modelzoo files, with\n",
    "    trained parameters and all.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def loadJSON(filename):\n",
    "    pass\n",
    "\n",
    "def loadYAML(filename):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting laminarflow/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile laminarflow/__init__.py\n",
    "from laminarflow._cruisecontrol import CruiseControl\n",
    "#from laminarflow._filedescriptors import loadDictlike\n",
    "#from laminarflow._filedescriptors import loadJSON\n",
    "#from laminarflow._filedescriptors import loadYAML\n",
    "#from laminarflow._filedescriptors import layer_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "import os\n",
    "from setuptools import setup\n",
    "\n",
    "# Utility function to read the README file.\n",
    "# Used for the long_description.  It's nice, because now 1) we have a top level\n",
    "# README file and 2) it's easier to type in the README file than to put a raw\n",
    "# string in below ...\n",
    "def read(fname):\n",
    "    return open(os.path.join(os.path.dirname(__file__), fname)).read()\n",
    "\n",
    "setup(\n",
    "    name = \"LaminarFlow\",\n",
    "    version = \"1.3.0.0\",\n",
    "    author = \"Chris Dusold\",\n",
    "    author_email = \"LaminarFlow@ChrisDusold.com\",\n",
    "    description = (\"A meta class to wrap and automate TensorFlow.\"),\n",
    "    license = read(\"LICENSE\"),\n",
    "    keywords = \"TensorFlow\",\n",
    "    #url = \"http://laminarflow.rtfd.org/\",\n",
    "    packages=['laminarflow'],\n",
    "    long_description=read('README.md'),\n",
    "    install_requires=['pyyaml'],\n",
    "    classifiers=[\n",
    "        \"Development Status :: 4 - Beta\",\n",
    "        \"Intended Audience :: Developers\",\n",
    "        \"Intended Audience :: Science/Research\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Natural Language :: English\",\n",
    "        \"Operating System :: OS Independent\", #Hopefully.\n",
    "        \"Programming Language :: Python\",\n",
    "        \"Topic :: Scientific/Engineering\",\n",
    "        \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n",
    "        \"Topic :: Utilities\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def clu(x, outdim, indim=None):\n",
    "    if indim:\n",
    "        try:\n",
    "            indim = list(indim)\n",
    "        except:\n",
    "            indim = [indim]\n",
    "    else:\n",
    "        indim = x.get_shape()[1:].as_list()\n",
    "    try:\n",
    "        outdim = list(outdim)\n",
    "    except:\n",
    "        outdim = [outdim]\n",
    "    C = tf.get_variable(\"C\", initializer=tf.truncated_normal(indim+outdim, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.truncated_normal(outdim, stddev=0.1))\n",
    "    cluKernel = -tf.reduce_sum(tf.abs(tf.sub(tf.expand_dims(x,len(indim)+1),\n",
    "                                             tf.expand_dims(C,0))),\n",
    "                               1) + b\n",
    "    cluKernel._C = C\n",
    "    cluKernel._b = b\n",
    "    return cluKernel\n",
    "\n",
    "def lin(x, shape):\n",
    "    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.truncated_normal(shape[1:], stddev=0.1))\n",
    "    linKernel = tf.matmul(x,W) + b\n",
    "    linKernel._W = W\n",
    "    linKernel._b = b\n",
    "    return linKernel\n",
    "\n",
    "#Convolution and Maxpool shortcuts\n",
    "def conv2d(x, shape):\n",
    "    W = tf.get_variable(\"W\", initializer=tf.truncated_normal(shape, stddev=0.1))\n",
    "    b = tf.get_variable(\"b\", initializer=tf.constant(0.1, shape=shape[-1:]))\n",
    "    convKernel = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "    convKernel._W = W\n",
    "    convKernel._b = b\n",
    "    return convKernel\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def cross_entropy(y,yhat):\n",
    "    return -tf.reduce_sum(y*tf.log(yhat + 1e-9)) #Without epsilon, it crashes.\n",
    "\n",
    "def accuracy_test(y,yhat):\n",
    "    correct_prediction = tf.equal(tf.argmax(yhat,1), tf.argmax(y,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f5a1bdfec18>}\n",
      "add\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f5a1bdfec18>}\n",
      "add\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f5a1bdfec18>, <tensorflow.python.ops.variables.Variable object at 0x7f5a1b5954a8>, <tensorflow.python.ops.variables.Variable object at 0x7f59f55700f0>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<laminarflow._cruisecontrol.CruiseControl at 0x7f5a1bdeddd8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from laminarflow import CruiseControl\n",
    "\n",
    "test = CruiseControl(\"test\")\n",
    "test.add('input',tf.placeholder, \"float\", shape=[None, 784])\n",
    "#test.add('expected_output', tf.placeholder, \"float\", shape=[None, 10])\n",
    "test.add('h', lin, test.input,[784,10])\n",
    "test.add('output', tf.nn.softmax, test.h)\n",
    "#test.add('optim', tf.train.AdadeltaOptimizer, 1e-4)\n",
    "#test.add('loss', cross_entropy, test.expected_output, test.output)\n",
    "#test.add('train_step', test.optim.minimize, test.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter\n",
      "sess\n",
      "1\n",
      "load\n",
      "enter\n",
      "sess\n",
      "2\n",
      "exit\n",
      "save\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f5a1b5954a8>, <tensorflow.python.ops.variables.Variable object at 0x7f59f55700f0>}\n",
      "Tensor(\"7f5a1bdeddd8/h/b/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"7f5a1bdeddd8/h/W/read:0\", shape=(784, 10), dtype=float32)\n",
      "1\n",
      "[[  2.01178156e-02   1.76191106e-01   2.41327912e-01   1.83001370e-03\n",
      "    1.02801770e-02   7.52868014e-04   2.48486991e-04   3.14141423e-01\n",
      "    2.17452794e-01   1.76572651e-02]]\n",
      "[[  2.01178156e-02   1.76191106e-01   2.41327912e-01   1.83001370e-03\n",
      "    1.02801770e-02   7.52868014e-04   2.48486991e-04   3.14141423e-01\n",
      "    2.17452794e-01   1.76572651e-02]]\n",
      "exit\n",
      "save\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f5a1b5954a8>, <tensorflow.python.ops.variables.Variable object at 0x7f59f55700f0>}\n",
      "Tensor(\"7f5a1bdeddd8/h/b/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"7f5a1bdeddd8/h/W/read:0\", shape=(784, 10), dtype=float32)\n",
      "0\n",
      "enter\n",
      "sess\n",
      "1\n",
      "load\n",
      "enter\n",
      "sess\n",
      "2\n",
      "exit\n",
      "save\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f5a1b5954a8>, <tensorflow.python.ops.variables.Variable object at 0x7f59f55700f0>}\n",
      "Tensor(\"7f5a1bdeddd8/h/b/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"7f5a1bdeddd8/h/W/read:0\", shape=(784, 10), dtype=float32)\n",
      "1\n",
      "[[  2.01178156e-02   1.76191106e-01   2.41327912e-01   1.83001370e-03\n",
      "    1.02801770e-02   7.52868014e-04   2.48486991e-04   3.14141423e-01\n",
      "    2.17452794e-01   1.76572651e-02]]\n",
      "exit\n",
      "save\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f5a1b5954a8>, <tensorflow.python.ops.variables.Variable object at 0x7f59f55700f0>}\n",
      "Tensor(\"7f5a1bdeddd8/h/b/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"7f5a1bdeddd8/h/W/read:0\", shape=(784, 10), dtype=float32)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f59f57e7c50>}\n",
      "add\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f59f57e7c50>}\n",
      "add\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f59ec187da0>, <tensorflow.python.ops.variables.Variable object at 0x7f59ec17f7b8>, <tensorflow.python.ops.variables.Variable object at 0x7f59f57e7c50>}\n",
      "enter\n",
      "sess\n",
      "1\n",
      "load\n",
      "enter\n",
      "sess\n",
      "2\n",
      "exit\n",
      "save\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f59ec187da0>, <tensorflow.python.ops.variables.Variable object at 0x7f59ec17f7b8>}\n",
      "Tensor(\"7f5a1b5bd9b0/h/b/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"7f5a1b5bd9b0/h/W/read:0\", shape=(784, 10), dtype=float32)\n",
      "1\n",
      "[[  2.01178156e-02   1.76191106e-01   2.41327912e-01   1.83001370e-03\n",
      "    1.02801770e-02   7.52868014e-04   2.48486991e-04   3.14141423e-01\n",
      "    2.17452794e-01   1.76572651e-02]]\n",
      "exit\n",
      "save\n",
      "{<tensorflow.python.ops.variables.Variable object at 0x7f59ec187da0>, <tensorflow.python.ops.variables.Variable object at 0x7f59ec17f7b8>}\n",
      "Tensor(\"7f5a1b5bd9b0/h/b/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"7f5a1b5bd9b0/h/W/read:0\", shape=(784, 10), dtype=float32)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "test2 = pkl.loads(pkl.dumps(test))\n",
    "with test2 as sess:\n",
    "    print(test2.output.eval({test2.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.91621422e-03   2.82290950e-02   2.67429184e-02   8.02965078e-04\n",
      "    4.82511277e-05   9.30676281e-01   7.31190317e-04   1.91889732e-04\n",
      "    8.63836240e-03   2.26531192e-05]]\n",
      "[[  1.39723779e-04   5.80451684e-03   2.04441160e-01   1.72922730e-01\n",
      "    3.24747467e-04   5.88755645e-02   2.04511788e-02   8.05121437e-02\n",
      "    1.72266200e-01   2.84262031e-01]]\n"
     ]
    }
   ],
   "source": [
    "test = CruiseControl(\"test\")\n",
    "test.add('input',tf.placeholder, \"float\", shape=[None, 784])\n",
    "test.add('expected_output', tf.placeholder, \"float\", shape=[None, 10])\n",
    "test.add('h', lin, test.input,[784,10])\n",
    "test.add('output', tf.nn.softmax, test.h)\n",
    "test.add('optim', tf.train.AdadeltaOptimizer, 1e-4)\n",
    "test.add('loss', cross_entropy, test.expected_output, test.output)\n",
    "test.add('train_step', test.optim.minimize, test.loss)\n",
    "#testing\n",
    "test._initialized = set(x for x in test._vars)\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "print(test.run(test.output,feed_dict={test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"7f956810a0b8_6/loss/Neg/Adadelta/read:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(test.optim._zeros_slot(test.loss, 'accum_update', test.optim._name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7f956810a0b8_6/loss/Neg/Adadelta:0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.optim.get_slot(test.loss, 'accum_update').name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test2/W:0']\n"
     ]
    }
   ],
   "source": [
    "print([i.name for i in tf.trainable_variables()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'minimize'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._var_pkl[6][1].method_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.69830758e-03   4.72098218e-05   5.72629273e-01   2.15697964e-03\n",
      "    5.06564493e-06   2.91877985e-02   2.15289459e-01   9.44951400e-02\n",
      "    8.30261037e-02   1.46463246e-03]]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "test2 = pkl.loads(pkl.dumps(test))\n",
    "with test2 as sess:\n",
    "    print(test2.output.eval({test2.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.56685505e-02   8.00773734e-04   6.37518406e-01   4.62362124e-03\n",
      "    1.42823666e-01   1.12912012e-03   2.60556606e-03   2.78750435e-04\n",
      "    1.93829164e-01   7.22434314e-04]]\n",
      "[[ 0.08158474  0.12712577  0.09410271  0.06918326  0.1128696   0.11112418\n",
      "   0.08440532  0.11400516  0.14154947  0.06404966]]\n"
     ]
    }
   ],
   "source": [
    "test.add('relu', tf.nn.relu, test.h)\n",
    "test.add('h2', lin, test.relu, [10,10])\n",
    "test.add('output2', tf.nn.softmax, test.h2)\n",
    "test.add('loss2', cross_entropy, test.expected_output, test.output2)\n",
    "test.add('train_step2', test.optim.minimize, test.loss2)\n",
    "with test as sess:\n",
    "    print(test.output.eval({test.input:np.ones([1,784])}))\n",
    "with test as sess:\n",
    "    print(test.output2.eval({test.input:np.ones([1,784])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AdadeltaOptimizer' object has no attribute '_get_or_create_slot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f195d529777b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_or_create_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'accum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'AdadeltaOptimizer' object has no attribute '_get_or_create_slot'"
     ]
    }
   ],
   "source": [
    "test.optim._get_or_create_slot(test.loss2,'accum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d253bd7304d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_variable_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "tf.is_variable_initialized(t).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"test2\"):\n",
    "    test = {}\n",
    "    test['in'] = tf.placeholder(\"float\", shape=[1,2])\n",
    "    test['out'] = tf.placeholder(\"float\", shape=[1,3])\n",
    "    test['W'] = tf.get_variable(\"W\", shape=[2,3])\n",
    "    test['loss'] = tf.nn.l2_loss(tf.matmul(test['in'], test['W']) - test['out'])\n",
    "    test['optim'] = tf.train.AdadeltaOptimizer()\n",
    "    test['train_step'] = test['optim'].minimize(test['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test2/Adadelta'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['train_step'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x7f95ab2c43c8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f957815b748>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f95681b3a90>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f95681b3fd0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7f95781c5908_6/loss/Neg/Adadelta:0',\n",
       " 'test2/W:0',\n",
       " 'test2/test2/W/Adadelta:0',\n",
       " 'test2/test2/W/Adadelta_1:0']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.name for i in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable test2/test2/W/Adadelta_1:0 does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f600f68d986b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mWAda1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adadelta_1:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m   1022\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m       custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    848\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m           custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    344\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m           validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape)\u001b[0m\n\u001b[1;32m    329\u001b[0m           \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m           caching_device=caching_device, validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape)\u001b[0m\n\u001b[1;32m    648\u001b[0m       raise ValueError(\"Variable %s does not exist, or was not created with \"\n\u001b[1;32m    649\u001b[0m                        \u001b[0;34m\"tf.get_variable(). Did you mean to set reuse=None in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                        \"VarScope?\" % name)\n\u001b[0m\u001b[1;32m    651\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitializing_from_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m       raise ValueError(\"Shape of a new variable (%s) must be fully defined, \"\n",
      "\u001b[0;31mValueError\u001b[0m: Variable test2/test2/W/Adadelta_1:0 does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "with tf.variable_scope(\"test2\", reuse=True):\n",
    "    W = tf.get_variable(\"W\")\n",
    "    #WAda = tf.get_variable(\"test2/W/Adadelta:0\")\n",
    "    with tf.variable_scope(\"test2\", reuse=True):\n",
    "        with tf.variable_scope(\"W\", reuse=True):\n",
    "            WAda1 = tf.get_variable(\"Adadelta_1:0\")\n",
    "            #Variable test2/test2/W/Adadelta_1:0 [...] was not created with tf.get_variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is this'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0} is {0}\".format(\"this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"{0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loss._shape_as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OVERLOADABLE_OPERATORS',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array_priority__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__invert__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_add_consumer',\n",
       " '_as_node_def_input',\n",
       " '_consumers',\n",
       " '_dtype',\n",
       " '_handle_dtype',\n",
       " '_handle_shape',\n",
       " '_op',\n",
       " '_override_operator',\n",
       " '_shape',\n",
       " '_shape_as_list',\n",
       " '_value_index',\n",
       " 'consumers',\n",
       " 'device',\n",
       " 'dtype',\n",
       " 'eval',\n",
       " 'get_shape',\n",
       " 'graph',\n",
       " 'name',\n",
       " 'op',\n",
       " 'set_shape',\n",
       " 'value_index'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dir(test.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor '7f956810a0b8_3/h/add:0' shape=(?, 10) dtype=float32>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in test.output.op.inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ControlDependenciesController',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_function',\n",
       " '_add_op',\n",
       " '_apply_device_functions',\n",
       " '_as_graph_def',\n",
       " '_as_graph_element_locked',\n",
       " '_attr_scope',\n",
       " '_attr_scope_map',\n",
       " '_building_function',\n",
       " '_check_not_finalized',\n",
       " '_collections',\n",
       " '_colocation_stack',\n",
       " '_container',\n",
       " '_control_dependencies_for_inputs',\n",
       " '_control_dependencies_stack',\n",
       " '_control_flow_context',\n",
       " '_current_control_dependencies',\n",
       " '_default_original_op',\n",
       " '_device_function_stack',\n",
       " '_finalized',\n",
       " '_functions',\n",
       " '_get_control_flow_context',\n",
       " '_get_function',\n",
       " '_gradient_override_map',\n",
       " '_graph_def_versions',\n",
       " '_handle_deleters',\n",
       " '_handle_feeders',\n",
       " '_handle_movers',\n",
       " '_handle_readers',\n",
       " '_is_function',\n",
       " '_kernel_label_map',\n",
       " '_last_id',\n",
       " '_lock',\n",
       " '_name_stack',\n",
       " '_names_in_use',\n",
       " '_next_id',\n",
       " '_next_id_counter',\n",
       " '_nodes_by_id',\n",
       " '_nodes_by_name',\n",
       " '_op_to_kernel_label_map',\n",
       " '_original_op',\n",
       " '_pop_control_dependencies_controller',\n",
       " '_push_control_dependencies_controller',\n",
       " '_record_op_seen_by_control_dependencies',\n",
       " '_registered_ops',\n",
       " '_seed',\n",
       " '_set_control_flow_context',\n",
       " '_unfeedable_tensors',\n",
       " '_unfetchable_ops',\n",
       " '_unsafe_unfinalize',\n",
       " '_version',\n",
       " 'add_to_collection',\n",
       " 'add_to_collections',\n",
       " 'as_default',\n",
       " 'as_graph_def',\n",
       " 'as_graph_element',\n",
       " 'building_function',\n",
       " 'clear_collection',\n",
       " 'colocate_with',\n",
       " 'container',\n",
       " 'control_dependencies',\n",
       " 'create_op',\n",
       " 'device',\n",
       " 'finalize',\n",
       " 'finalized',\n",
       " 'get_all_collection_keys',\n",
       " 'get_collection',\n",
       " 'get_collection_ref',\n",
       " 'get_operation_by_name',\n",
       " 'get_operations',\n",
       " 'get_tensor_by_name',\n",
       " 'gradient_override_map',\n",
       " 'graph_def_versions',\n",
       " 'is_feedable',\n",
       " 'is_fetchable',\n",
       " 'name_scope',\n",
       " 'prevent_feeding',\n",
       " 'prevent_fetching',\n",
       " 'seed',\n",
       " 'unique_name',\n",
       " 'version']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(test.output.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor '7f956810a0b8_1/input/Placeholder:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.output.graph.get_tensor_by_name(test.input.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.output.graph.is_feedable(test.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.name for i in test._vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'ref' of 'IsVariableInitialized' Op requires l-value input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-96c74a672fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_variable_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mis_variable_initialized\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0minitialized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m   \"\"\"\n\u001b[0;32m-> 1223\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_variable_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36mis_variable_initialized\u001b[0;34m(ref, name)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m   \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IsVariableInitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    611\u001b[0m             raise TypeError(\n\u001b[1;32m    612\u001b[0m                 \u001b[0;34m\"Input '%s' of '%s' Op requires l-value input\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m                 (input_name, op_type_name))\n\u001b[0m\u001b[1;32m    614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'ref' of 'IsVariableInitialized' Op requires l-value input"
     ]
    }
   ],
   "source": [
    "tf.is_variable_initialized(test.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7f956810a128>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._sess.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-8bc19386ad13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3622\u001b[0m                        \"`eval(session=sess)`\")\n\u001b[1;32m   3623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m       raise ValueError(\"Cannot use the default session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   3625\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m                        \u001b[0;34m\"graph. Pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use the default session to evaluate tensor: the tensor's graph is different from the session's graph. Pass an explicit session to `eval(session=sess)`."
     ]
    }
   ],
   "source": [
    "with sess:\n",
    "    test.expected_output.eval(feed_dict={test.expected_output:np.ones([1,10])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name '7f956810a0b8_1/input/Placeholder:0' refers to a Tensor which does not exist. The operation, '7f956810a0b8_1/input/Placeholder', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-d30506e462cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2465\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\"\n\u001b[1;32m   2466\u001b[0m                       % type(name).__name__)\n\u001b[0;32m-> 2467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2358\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   2359\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2360\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   2361\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name '7f956810a0b8_1/input/Placeholder:0' refers to a Tensor which does not exist. The operation, '7f956810a0b8_1/input/Placeholder', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "tf.Graph().get_tensor_by_name(test.input.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name '7f956810a0b8_3/h/add:0' refers to a Tensor which does not exist. The operation, '7f956810a0b8_3/h/add', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2af5608b0cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2465\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\"\n\u001b[1;32m   2466\u001b[0m                       % type(name).__name__)\n\u001b[0;32m-> 2467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/poik/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2358\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   2359\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2360\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   2361\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name '7f956810a0b8_3/h/add:0' refers to a Tensor which does not exist. The operation, '7f956810a0b8_3/h/add', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(test.h.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor '7f956810a0b8_1/input/Placeholder:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.unique_name(test.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x7f95680ae710>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "g.as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    a = tf.placeholder('float',shape=[None,10])\n",
    "    b = tf.placeholder('float',shape=[10,1])\n",
    "    out = a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g):\n",
    "    print(out.eval(feed_dict={a:np.ones([10,10]),b:[[1],[1],[1],[1],[1],[1],[1],[1],[1],[1]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
